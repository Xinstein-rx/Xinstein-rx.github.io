<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>Logistic 回归 | Xinsteinのblog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 6.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Logistic 回归</h1><a id="logo" href="/.">Xinsteinのblog</a><p class="description">Brainy is the new sexy.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Logistic 回归</h1><div class="post-meta">2020-05-16</div><div class="post-content"><h2 id="为什么不用线性回归"><a href="#为什么不用线性回归" class="headerlink" title="为什么不用线性回归"></a>为什么不用线性回归</h2><p>Logistic 回归是一种分类算法。一开始我们也想把线性回归用于这种分类的算法，给线性回归函数设置一个阈值，大于这个值的所有 <em>x</em> 归为一类值，小于的归为另一类。但是线性回归不总是能找出一条合适的直线和阈值，如图3.1所示，并且分类一般的取值都是 0，1，线性回归的函数值有可能比 0 小很多，也可能比 1 大很多，这样看起来很奇怪，于是得用 Logistic 回归，Logistic 函数的函数值固定在 [0,1] 之间。</p>
<span id="more"></span>

<div align = center>
    <img src = "Logistic-回归\4.PNG">
</div>

<center>Fig1. 线性回归不好的例子</center>

<h2 id="Logistic-回归"><a href="#Logistic-回归" class="headerlink" title="Logistic 回归"></a><strong>Logistic</strong> 回归</h2><h3 id="假设函数"><a href="#假设函数" class="headerlink" title="假设函数"></a>假设函数</h3><p>Logistic 回归与一般线性回归的不同点在于，Logistic 回归将线性回归得到的函数，通过一个激活函数映射到了一个非线性的情况，Logistic 回归的假设函数如下<br>$$<br>h_\theta(x)&#x3D;\dfrac{1}{1+e^{-\theta^Tx}}<br>$$<br>上面公式是一个复合版本，过程函数如下</p>
<p>先是一个线性回归<br>$$<br>h_\theta(x)&#x3D;\theta^Tx<br>$$<br>再将线性回归得出来的值，带入一个激活函数，激活函数有很多，一般比较常用的是sigmoid 函数，见图2<br>$$<br>g(z)&#x3D;\dfrac{1}{1+e^{-z}}<br>$$</p>
<div align = center>
    <img src = "Logistic-回归\5.PNG">
</div>

<center>Fig2. sigmoid函数</center>

<p>可以这样来理解 Logistic 的假设函数，即我输入一个 x，我将有多大的概率知道，在给定参数的情况下，这个 x 属于哪一类<br>$$<br>P(y&#x3D;1|x;\theta) + P(y&#x3D;0|x;\theta)&#x3D;1	<br>$$</p>
<h3 id="如何预测"><a href="#如何预测" class="headerlink" title="如何预测"></a>如何预测</h3><p>我们把分类的规则定义如下：</p>
<blockquote>
<p><strong>Definition 1</strong> 假设函数的预测规则：</p>
<p>”y &#x3D; 1” if $h_\theta(x) \ge 0.5$ 即 $ \theta^Tx \ge 0 $</p>
<p>”y &#x3D; 0” if $h_\theta(x) \ne 0.5$ 即 $\theta^Tx \ne 0$ </p>
</blockquote>
<h3 id="决策界限"><a href="#决策界限" class="headerlink" title="决策界限"></a>决策界限</h3><p>决策界限简单来说就是第一步线性回归得到的线性假设函数的图，见图3</p>
<p>决策界限不是数据集的特性，而是假设函数的特性，一旦假设函数中的参数确定了，决策界限也就确定了，不过，参数的拟合需要用数据集来拟合。</p>
<div align = center>
    <img src = "Logistic-回归\6.PNG">
</div>

<center>Fig3. 紫红色为决策界限</center>

<p>决策界限也不都是直线，当需要一个曲线作为决策界限时，可以在线性回归的方程中，增加高阶项来拟合，见图4。增加线性回归中的阶数，还将有可能得到更复杂的决策界限。</p>
<div align = center>
    <img src = "Logistic-回归\7.PNG">
</div>

<center>Fig4. 增加高阶项的例子</center>

<h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>一开始我们想用线性回归的代价函数来作为 Logistic 的代价函数，但是因为 Logistic</p>
<p>回归的假设函数不是一个线性的，因此用线性回归的代价函数的话，回导致代价函数不是</p>
<p>一个凸函数，会有很多的局部最优值。因此我们用下面的函数来作为 Logistic 回归的代价</p>
<p>函数：</p>
<blockquote>
<p><strong>Theorem 4.1</strong><br>$$<br>J(\theta)&#x3D;\frac{1}{m}\sum_{1}^{m}cost(h_\theta(x^{(i)}), y^{(i)})\<br>cost(h_\theta(x), y))&#x3D;<br>        \begin{cases}<br>        -log(h_\theta(x)) &amp; \text{if } y &#x3D; 1,\<br>        -log(1-h_\theta(x)) &amp; \text{if } y &#x3D; 0<br>        \end{cases}<br>$$</p>
</blockquote>
<p>直观的来理解一下这个代价函数，<em>y</em> &#x3D; 1 时的代价函数如图5，<em>y</em> &#x3D; 2 时的代价</p>
<p>函数如图6</p>
<div align = center>
    <img src = "Logistic-回归\8.PNG">
    <img src = "Logistic-回归\9.PNG">
</div>

<center>Fig5. y=1 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Fig6. y = 0</center>

<p>当 <em>y</em> &#x3D; 1 时，预测值 <em>h**θ</em>(<em>x</em>) &#x3D; 0 代价就会很大，这也符合我们的假设，因为这时候 <em>y</em> &#x3D; 1，与我们的预期完全不符，所以代价就会非常大，反之当预测值为 1 时，代价就是 0，因为这时候完全预测对了。反之，当 <em>y</em> &#x3D; 0 时的分析也是一样的。</p>
<p>通过这种方法得到的代价函数就会是一个凸函数，有全局的最优值。</p>
<p>代价函数 cots 的简化形式：<br>$$<br>cost(h_\theta(x), y))&#x3D; -ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))<br>$$<br>因此代价函数可以写成</p>
<blockquote>
<p>$$<br>J(\theta) &#x3D; -\frac{1}{m}[\sum_{i&#x3D;1}^{m}y^{(i)}log(h_\theta(x^{(i)}))+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]<br>$$</p>
</blockquote>
<h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><p>Logistic 回归的梯度下降法和线性回归的梯度下降的形式是一样的</p>
<blockquote>
<p><strong>Theorem 2</strong> <em>Logistic’s Gradient descent algorithm</em></p>
<p>repeat :<br>$$<br>\theta_j:&#x3D;\theta_j-\alpha\frac{\delta}{\delta \theta_j}J(\theta)\<br>\theta_j:&#x3D;\theta_j-\alpha\frac{1}{m}\sum_{1}^{m}(h_\theta(x^{(i)}) - y^{(i)})\cdot x^{(i)}_j<br>$$</p>
</blockquote>
<p>但是不能说线性回归的梯度下降和 Logistic 回归的梯度下降是一个算法，因为他们的</p>
<p>$h_\theta(x)$函数是不一样的。</p>
<h3 id="多类别分类"><a href="#多类别分类" class="headerlink" title="多类别分类"></a>多类别分类</h3><p>多类别分类的一般思想就是，如果有 m 个类，就训练 m 个分类器，每个分类器可以确定一类，要是有一个输入 <em>x</em>，就选择，分类器输出值最大的那一类，即 max <em>h</em>(<em>i</em>) <em>θ</em> (<em>x</em>), 具体过程见图7</p>
<div align = center>
    <img src = "Logistic-回归\10.PNG">
</div>

<center>Fig7. 多元分类</center></div><div class="tags"><a href="/tags/机器学习"><i class="fa fa-tag">机器学习</i></a></div><div class="post-nav"><a class="pre" href="/2020/05/16/%E6%AD%A3%E5%88%99%E5%8C%96/">正则化</a><a class="next" href="/2020/05/16/1062-Talent-and-Virtue-25%E5%88%86/">1062 Talent and Virtue (25分)</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="About"><img class="nofancybox" src="/img/avatar.png"/></a><p>To be a better man.</p><a class="info-icon" href="https://twitter.com/username" title="Twitter" target="_blank" style="margin-inline:5px"> <i class="fa fa-twitter-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:admin@domain.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/username" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/PAT-Advanced/" style="font-size: 15px;">PAT-Advanced</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/dfs/" style="font-size: 15px;">dfs</a> <a href="/tags/%E4%BA%8C%E5%88%86/" style="font-size: 15px;">二分</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E5%9B%BE%E8%AE%BA/" style="font-size: 15px;">图论</a> <a href="/tags/%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F/" style="font-size: 15px;">连通分量</a> <a href="/tags/%E6%A8%A1%E6%8B%9F/" style="font-size: 15px;">模拟</a> <a href="/tags/map/" style="font-size: 15px;">map</a> <a href="/tags/%E9%9B%86%E5%90%88/" style="font-size: 15px;">集合</a> <a href="/tags/%E6%A0%91%E7%9A%84%E7%9B%B4%E5%BE%84/" style="font-size: 15px;">树的直径</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E6%80%9D%E7%BB%B4/" style="font-size: 15px;">思维</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 15px;">动态规划</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" style="font-size: 15px;">字符串</a> <a href="/tags/%E6%99%BA%E5%8A%9B%E9%A2%98/" style="font-size: 15px;">智力题</a> <a href="/tags/%E5%BF%AB%E6%8E%92/" style="font-size: 15px;">快排</a> <a href="/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">插入排序</a> <a href="/tags/%E5%A0%86/" style="font-size: 15px;">堆</a> <a href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" style="font-size: 15px;">并查集</a> <a href="/tags/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/" style="font-size: 15px;">优先队列</a> <a href="/tags/%E6%95%A3%E5%88%97/" style="font-size: 15px;">散列</a> <a href="/tags/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">拓扑排序</a> <a href="/tags/STL/" style="font-size: 15px;">STL</a> <a href="/tags/Git/" style="font-size: 15px;">Git</a> <a href="/tags/%E8%A7%84%E8%8C%83/" style="font-size: 15px;">规范</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E6%9C%80%E7%9F%AD%E8%B7%AF/" style="font-size: 15px;">最短路</a> <a href="/tags/Dijkstra/" style="font-size: 15px;">Dijkstra</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Tableau%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 15px;">Tableau数据分析</a> <a href="/tags/cookie/" style="font-size: 15px;">cookie</a> <a href="/tags/session/" style="font-size: 15px;">session</a> <a href="/tags/UML/" style="font-size: 15px;">UML</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/" style="font-size: 15px;">软件工程</a> <a href="/tags/servlet/" style="font-size: 15px;">servlet</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 15px;">数据库</a> <a href="/tags/mongodb/" style="font-size: 15px;">mongodb</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/OS/" style="font-size: 15px;">OS</a> <a href="/tags/%E5%B0%8F%E7%8E%A9%E5%85%B7/" style="font-size: 15px;">小玩具</a> <a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size: 15px;">回溯</a> <a href="/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/" style="font-size: 15px;">贪心算法</a> <a href="/tags/%E5%8C%BA%E9%97%B4%E9%97%AE%E9%A2%98/" style="font-size: 15px;">区间问题</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 15px;">二叉树</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">深度学习</a> <a href="/tags/CNN/" style="font-size: 15px;">CNN</a> <a href="/tags/%E5%BE%AA%E7%8E%AF%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">循环序列模型</a> <a href="/tags/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/" style="font-size: 15px;">白盒测试</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" style="font-size: 15px;">论文研读</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" style="font-size: 15px;">计算机视觉</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/12/24/C-STL%E4%B9%8Bupper-bound%E5%92%8Clower-bound/">C++STL之lower_bound & upper_bound</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/12/14/%E3%80%90OS%E3%80%91%E7%AC%AC%E4%B8%89%E5%A4%A9-%E8%BF%9B%E5%85%A532%E4%BD%8D%E6%A8%A1%E5%BC%8F%E5%B9%B6%E5%AF%BC%E5%85%A5c%E8%AF%AD%E8%A8%80/">【OS】第三天 进入32位模式并导入c语言</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/12/14/%E3%80%90OS%E3%80%91%E7%AC%AC%E4%BA%8C%E5%A4%A9-%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B8%8Emakefile%E5%85%A5%E9%97%A8/">【OS】第二天 汇编语言学习与makefile入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/12/14/%E3%80%90OS%E3%80%91%E7%AC%AC%E4%B8%80%E5%A4%A9-%E4%BB%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E5%88%B0%E6%B1%87%E7%BC%96%E7%A8%8B%E5%BA%8F%E5%85%A5%E9%97%A8/">【OS】第一天 从计算机结构到汇编程序入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/29/%E3%80%90%E9%93%BE%E8%A1%A8%E6%80%BB%E7%BB%93%E3%80%91%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%E5%B0%B1%E6%98%AF%E7%89%9B%EF%BD%9E/">【链表总结】快慢指针就是牛～</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/29/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%9D%9E%E9%80%92%E5%BD%92%E9%81%8D%E5%8E%86/">二叉树的非递归遍历</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/25/%E3%80%90%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E3%80%91%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%E4%BA%8C%EF%BC%9A%E5%8C%BA%E9%97%B4%E9%97%AE%E9%A2%98/">【贪心算法】贪心算法系列二：区间问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/25/%E3%80%90%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E3%80%91%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%E4%B8%80/">【贪心算法】贪心算法系列一</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/07/03/%E3%80%90%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%E3%80%91%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/">【回溯算法】回溯算法总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/06/21/%E3%80%90%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/">【动态规划】动态规划总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/." rel="nofollow">Xinsteinのblog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>