<!DOCTYPE html><html lang="en"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content=""><title>【论文研读】-ImageNet Classification with Deep Convolutional Neural Networks | Xinsteinのblog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/latest/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/latest/grids-responsive-min.min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/latest/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//lib.baomitu.com/clipboard.js/latest/clipboard.min.js"></script><script type="text/javascript" src="//lib.baomitu.com/toastr.js/latest/toastr.min.js"></script><link rel="stylesheet" href="//lib.baomitu.com/toastr.js/latest/toastr.min.css"><meta name="generator" content="Hexo 6.2.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">【论文研读】-ImageNet Classification with Deep Convolutional Neural Networks</h1><a id="logo" href="/.">Xinsteinのblog</a><p class="description">Brainy is the new sexy.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> Home</i></a><a href="/archives/"><i class="fa fa-archive"> Archive</i></a><a href="/about/"><i class="fa fa-user"> About</i></a><a href="/atom.xml"><i class="fa fa-rss"> RSS</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">【论文研读】-ImageNet Classification with Deep Convolutional Neural Networks</h1><div class="post-meta">2020-05-25</div><div class="post-content"><h2 id="使用深度卷积神经网络对ImageNet图像分类"><a href="#使用深度卷积神经网络对ImageNet图像分类" class="headerlink" title="使用深度卷积神经网络对ImageNet图像分类"></a>使用深度卷积神经网络对ImageNet图像分类</h2><h3 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h3><ul>
<li>2012年ImageNet图像分类竟赛冠军</li>
<li>首次将卷积神经网络CNN和深度学习DL用于大规模图像分类并且性能优异</li>
</ul>
<p>AlexNet之后的视觉模型，不管是图像分类、目标检测还是语义分割，都是在AlexNet的基础上，使用深度卷积神经网络提取图像深层特征。</p>
<h3 id="abstract"><a href="#abstract" class="headerlink" title="abstract"></a>abstract</h3><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h3><p>目前的图像识别方法都是基于传统的机器学习的，在小规模的数据集上，可以有很好的性能，但是到了现实世界中，机器学习的表现就不那么好了。因此，需要更大规模的数据集。卷积神经网络以其拥有的局部连接、权值共享、逐层堆叠、下采样、卷积核，和我们真实处理视觉的流程是比较类似的，局部连接和权值共享保留了相邻像素依赖性。因此卷积神经网络比较适合解决计算机视觉问题。</p>
<p>当前的硬件能力已经实现了高度优化的二维卷积，以及足够庞大的ImageNet数据集，可以防止过拟合问题。</p>
<h3 id="2-The-Dataset"><a href="#2-The-Dataset" class="headerlink" title="2 The Dataset"></a>2 The Dataset</h3><p>​	ImageNet是一个庞大的数据集，拥有1500万张标注好的高分辨率的图片，被分成了22000各类别。数据集是从网络上收集并进行人工标注的。在ImageNet中有两个评估模型的指标，top-1和top-5。top-1是网络预测最高的结果，就是正确标签的结果；top-5是网络预测率最高的前五个标签的结果，top-5看起来比较科学。</p>
<p>ImageNet中图片的大小和分辨率都是不同的，单数卷积神经网络需要固定大小的图片，因此对图片进行下采样，将图片大小全部转换为256*256的正方形图片。方法是，将图片的短边重新rescaled到256像素，然后在图片中剪出一个patch。然后进行预处理，每个像素减去对应维度的统计平均值，即中心化处理。（一开始没有明白这里，从网上查了一下，这样做的原因是消除图片中的公共部分，凸显个体之间的特征和差异，即把图片中最有特征的东西保留下来，减少对噪声的敏感性）。</p>
<h3 id="3-The-Architecture"><a href="#3-The-Architecture" class="headerlink" title="3 The Architecture"></a>3 The Architecture</h3><p>五个卷积层，三个全连接层。如图1</p>
<div align = center>
    <img src = 【论文研读】-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/1.PNG> <br><br>
    Fig1. AlexNet架构
</div>

<p>值得注意的地方是，上述图片中输入图片的大小224 x 224应该是227 x 227。图片之所以画成两部分，是因为以当时的计算水平，还无法在一GPU上进行训练，因此将网络分到了两个GPU上进行训练，GPU之间互相的进行信息传递。</p>
<h4 id="ReLU-Nonlinearity"><a href="#ReLU-Nonlinearity" class="headerlink" title="ReLU Nonlinearity"></a>ReLU Nonlinearity</h4><p>AlexNet一个人创新的地方就是用了ReLU（修正线性单元）非线性激活函数。常用的sigmoid和tanh激活函数都有一个饱和问题，就是当输入很大或是很小的时候，经过激活函数得到的值，差别就会很小，这就可能会造成梯度消失问题。因此这两个激活函数，对于训练超大型的网络会有些困难。ReLU激活函数为ReLU(x) &#x3D; max(0,x)，不存在饱和问题，因此在训练的时候就避免的梯度下降问题</p>
<div align = center>
    <img src = 【论文研读】-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/4.PNG> <br><br>
    Fig2. 4层CNN在CIFAR-10上训练收敛至训练误差为0.25时ReLU比tanh快6倍
</div>

<p>$$<br>ReLU(x)&#x3D;max(0,x)<br>$$</p>
<p>$$<br>tanh(x)&#x3D;\dfrac{e^x-e^{-x}}{e^x+e^{-x}}<br>$$</p>
<p>ReLU激活函数不仅可以防止过拟合，还可以加速训练。前人也曾使用$f(x)&#x3D;|tanh(x)|$作为激活函数，并且在caltheh-101数据集上取得了不错的效果，但是由于ImageNet数据集很大，所以对速度要求就比较高。</p>
<h4 id="3-2-Training-on-Multiple-GPUs"><a href="#3-2-Training-on-Multiple-GPUs" class="headerlink" title="3.2 Training on Multiple GPUs"></a>3.2 Training on Multiple GPUs</h4><p>两个GPU并行计算。由于当时的技术限制，每个显存只有3GB，对于训练如此大型的神经网络来说是不够的，因此将网络分配到两个GPU上，进行并行计算，GPU之间可以进行信息交流而不需要通过内存。分配的策略是，将一半的神经元分配到GPU中，有的层进行GPU之间的通信，有的层不需要进行信息的交互（如图1）。</p>
<p>这样的并行计算分别把top-1和top-5的错误率降低了1.7%和1.2%。双CPU（全参数）比单GPU（半参数）训练时间更短。</p>
<p>单GPU并不是将网络砍一半，因为我们要保证，最后一个卷积层和全连接层的参数数量与双GPU（全参数）相同，因此“半参数”并非真的只有一半的参数。</p>
<h4 id="3-3-Local-Response-Normalization"><a href="#3-3-Local-Response-Normalization" class="headerlink" title="3.3 Local Response Normalization"></a>3.3 Local Response Normalization</h4><p>LRN局部对比度归一化：ReLU激活函数之后进行。它的作用时在同一个像素位置，防止很多的高激活。如果一个像素出现了高激活，他会对周围的像素进行抑制（类似于顶端优势），抑制他们的激活。</p>
<p>对于其他的激活函数要进行normalize来避免输入信号达到饱和（其实就是防止过拟合），而ReLU不需要。ReLU神经元的值如果不是0，就可以进行学习，是0的话，就不能进行学习。但是我们发现，仍然可以用局部响应归一化帮助模型泛化，泛化的意思就是防止过拟合。LRN函数为</p>
<div align = center>
    <img src = 【论文研读】-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/5.PNG>
</div>

<p>直观的理解这个公式是，当前像素的值当作分子，在不同channel相同位置前后几个像素的平方和作为分母，也就是把周围邻近的几个channel考虑进来，起到了侧向抑制的作用。k是为了防止分母为0，n是邻近的通道数，$\alpha \beta$是常数，$a^i_{x,y}$是feature map上(x,y)的值，N是本层channel的数量。$(k,\alpha,\beta,n)&#x3D;(0,1,1,N)$→普通的沿所有通道归一化；$(k,\alpha,\beta,n)&#x3D;(2,10^{-4},0.75,5)$→AlexNet 。我们在某些层的ReLU之后使用了LRN局部响应归一化。</p>
<p>其实在VGG的论文中，做了一个对比实验，证明了这个LRN层其实并没有什么实质的作用。在AlexNex论文中加入LRN层是会降低模型错误率的，但是现在基本不使用这个方法了。</p>
<h4 id="3-4-Overlapping-Pooling"><a href="#3-4-Overlapping-Pooling" class="headerlink" title="3.4 Overlapping Pooling"></a>3.4 Overlapping Pooling</h4><p>重叠池化：池化步长小于池化窗口。一般来说，普通的池化是不进行重叠的。在论文中采用stride&#x3D;2，size &#x3D; 3的池化方法，将top-1和top-5的错误率降低了0.4%和0.3%。论文中也说这个方法其实也起到了正则化，防止过拟合的作用。但其实现在重叠池化这个操作也已经不再被使用了。</p>
<h4 id="3-5-Overall-Architecture"><a href="#3-5-Overall-Architecture" class="headerlink" title="3.5 Overall Architecture"></a>3.5 Overall Architecture</h4><p>AlexNet的整体结构如图1。网络的目的是最大化一个多分类逻辑回归（softmax回归），其实就是最小化交叉熵损失函数，等效于最大化对数似然概率。我们要让所有的模型都被预测正确的概率乘积最大化，取个对数就是把和最大化，加上一个负号就是极大似然估计推出的交叉熵损失函数。 </p>
<p>网络的2，4，5层是GPU间没有交互的，第3层是两个GPU可以互相通信的，全连接层也是可以互相通信的。第1，2层在ReLU之后使用了LRN局部相应归一化，在1，2，5层使用了最大池化，ReLU是每一层都用到的。</p>
<p>原始图像大小为227 x 227.第一层卷积层是96个11 x 11 x 3的卷积核，步长为4；第二层卷积层是256个5 x 5 x 48 的卷积核；第三层卷积层是384个3 x 3 x 256的卷积核；第四层卷积层是384个3 x 3 x 192的卷积核；第五层卷积层是256个3 x 3 x 192的卷积核；全连接层每层4096个神经元。</p>
<h3 id="4-Reducing-Overfitting"><a href="#4-Reducing-Overfitting" class="headerlink" title="4 Reducing Overfitting"></a>4 Reducing Overfitting</h3><p>网络有60万个参数，因此会容易出现过拟合的现象。</p>
<h4 id="4-1-Data-Augmentation"><a href="#4-1-Data-Augmentation" class="headerlink" title="4.1 Data Augmentation"></a>4.1 Data Augmentation</h4><p>数据增强，人为扩充数据集。</p>
<p>平移翻转：利用Python代码就可以在处理当前图片的时候，下一张扩充的图片已经准备好，不需要将图片存储在硬盘上，因此数据增强不会引起额外的时间开销。利用平移和水平翻转的方法我们可以将一张图片增加到2048（32 x 32 x 2)张图片，主要方法是，在一张256 x 256的图片上裁剪出许多224 * 224 的小patch，水平方向可以裁剪出32张图片，竖直方向也可以裁剪出32张图片，每个小patch又可以进行翻转。对于测试集，只需要裁剪出5个224 x 224 的patch就可以，然后每个patch还可以翻转一下，将这10个图片喂到网络里，得到10个结果，对10个结果进行融合得到最终的对这张图片的分类结果。</p>
<p>颜色变换：利用主成分分析法（PCA）对图片进行颜色变换，对每一张图片，按照一定的方向，进行随机的颜色光度的变换，其实可以直接对原图进行光度变换，但是为了更接近自然，采取了主成分分析法，沿着主成分的方向，进行光度变换，是数据集更加贴近于自然图像。经过这样的训练，模型可以足够的鲁棒，对于不同光照的图片提取的更多是图片的语义信息，而不是空间信息。</p>
<h4 id="4-2-Dropout"><a href="#4-2-Dropout" class="headerlink" title="4.2 Dropout"></a>4.2 Dropout</h4><p>随即失活。对训练集上的每一个batch都随机掐死一半的神经元，即每一个神经元都有一半的概率被掐死，神经元被掐死的意思是，这个神经元的输出为0，阻断他的前向和反向传播，这是在预测阶段。在训练阶段，保留所有的神经元，但是对预测结果乘以0.5，这样才能在这个阶段输出结果的数学期望，和训练阶段掐死一半的神经元输出的数学期望相一致。其实这种随即失活的办法就相当于对不同网络的集成（每一步都随机选择一半的神经元），这个技巧能减少神经元之间的联合依赖适应性，减少过拟合，强迫每一个神经元都和随机不同的神经元协作，可以使网络更加的鲁棒。</p>
<h5 id="dropout能减少过拟合的原因"><a href="#dropout能减少过拟合的原因" class="headerlink" title="dropout能减少过拟合的原因"></a>dropout能减少过拟合的原因</h5><ul>
<li>对模型进行了集成。假设网络一层有10个神经元，每个神经元都有一般的概率被掐死，那么网络排列组合的个数就有2<sup>10</sup>种。起到一种集体做决策的效果。</li>
<li>记忆随机抹去。</li>
<li>减少神经元之间的联合依赖适应性，强迫每一个神经元都和随机不同的神经元协作。</li>
<li>和生物学中的有性繁殖有关，每个基因片段都要与来自另一个个体的基因片段协同工作。</li>
</ul>
<p>论文在两个全连接层使用了dorpout，因为神经元被掐死了一半，因此训练时间要加倍，才能弥补掐死的神经元不能学习到的信息。</p>
<h3 id="5-Details-of-learning"><a href="#5-Details-of-learning" class="headerlink" title="5 Details of learning"></a>5 Details of learning</h3><p>采用随机梯度下降的方法，每一个batch是128个样本，动量是0.9，权重衰减0.0005，权重衰减（每次下山迈的步子）就对应了损失函数里的正则化，起到了正则化的作用，降低了模型的训练误差。pytorch里的Adma优化器默认的weight decay就是0.0005。权重的优化更新按照如下方式进行：</p>
<div align = center>
    <img src = 【论文研读】-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/6.PNG>
</div>
$v_i$表示动量，加入动量的目的是防止梯度下降的时候被困在鞍点和局部最优点。最后一项是每一个batch的平均的一阶梯度，一阶梯度就是损失函数想对于每一个参数的一阶导数。

<p>随机初始化。每一个权重都是以0为均值，以0.01为标准差的正态分布，即权重W~（1，0.01）。2，4，5卷积层以及全连接的隐藏层偏置项全部为1 ，这是因为尽量一开始让ReLU都是正的激活；其他层的偏置项都设为0 。</p>
<p>开始使用一个同样大的学习率，当验证误差到了一个瓶颈，不再降低的时候，我们手动除以10.学习率初始化为0.01，在120万张数据上训练了90轮，在NVIDIA GTX 580 3GB GPUs上训练了6天。</p>
<h3 id="6-Results"><a href="#6-Results" class="headerlink" title="6 Results"></a>6 Results</h3><p>模型参加了ILSVRC-2012竞赛，因为这一年测试集标签没有公开，就是用验证集代替测试集，发现验证集和测试集的错误率是很类似的，大概差0.1%，所以可以用验证集上的误差，代替测试集上的误差。</p>
<div align = center>
    <img src = 【论文研读】-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/7.PNG>
</div>

<p>上表的第一项是，本篇论文所讲的CNN达到的错误率是18.2%；五个这样的模型集成，也就对应表格的第二项，错误率是16.4%；第三项是在5个卷积层后再加一个卷积层，先在ImageNet Fall 2011数据集上，进行预训练，再在2012年数据集上进行“fine-tuning”（微调），即进行一个迁移学习，能达到16.6%的错误率；把五个画*的模型与2个传统的AlexNet模型（就是本文讲的模型）进行集成，达到了15.3%的错误率。</p>
<p>我们还在ImageNet Fall 2009 数据集上进行了测试，数据集包含了18104个类别，890万张图片。在这个数据集上，我们采用了传统的划分训练集和数据集的方法，一半用于训练集，一半用于测试集，在这个测试集上，top-1和top-5的错误率为67.4%和40.9%，是在上述AlexNet的最后一个池化层后额外加了第六个卷积层。在这之前最好的结果是78.1%和60.9%。</p>
<h4 id="6-1Qualitative-Evaluations"><a href="#6-1Qualitative-Evaluations" class="headerlink" title="6.1	Qualitative Evaluations"></a>6.1	Qualitative Evaluations</h4><p>对一些样本的定性评估。</p>
<div align = center>
    <img src = 【论文研读】-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/2.PNG>
</div>

<p>上图是AlexNet的96个卷积核提取到的特征。前三行是第一个GPU训练得到的48个卷积核提取的边缘，频率方向的特征；后三行是第二个GPU训练得到的48个卷积核提取的颜色特征。这个现象很有趣，两个GPU在某些曾是可以进行通信的，但是他们训练所提出的特征是不一样的，这种特化，是在每次训练中都会出现的，是独立于权重初始化的。</p>
<div align = center>
    <img src = 【论文研读】-ImageNet-Classification-with-Deep-Convolutional-Neural-Networks/3.PNG>
</div>

<p>图片的左边是ILSVRC-2010测试集中的部分图片及模型预测结果，上面部分是正确预测，下面是错误预测，从正确预测中可以看出，即便是图片提供了一小部分信息，但是网络仍然可以做出准确的预测。正确预测中的第四张图片，网络给出的结果是豹子，其他的高分预测也都是和豹子有关的，说明我们的网络是可以提取到语义信息的。就算是错误的预测，也是可以给出相关的结果的，还有可能是因为标签的模糊性，导致了预测错误。</p>
<p>右边的图片要竖着来看。第一列是我们从ILSVRC-2010测试集中选出的图片，把这五张图片feed到网络里，从倒数第二个全连接层拿出一个4096维的向量，这个4096维的向量，就相当于我们网络提取到的特征，网络的在干的事情就是，把一张图片提取到的信息转化为一个4096维的向量，每一张图片都对应一个4096维的向量。从训练集中找到和第一列图片4096维向量欧式距离最小的6张原始图片，就可以找到上述的图片。我们发现，找出来的图片确实和给定的测试集的图片（就是第一列的图片）是比较像的。而且，图片的明暗并不影响网络的预测，这说明，网络提取的是语义信息，而不是像素空间信息。传统的图像检索模型，只是在逐一对比像素，而并没有考虑语义信息，是一个无监督的过程，现在我们就可以建立一个考虑语义特征的图形检索系统。</p>
<p>真是情况的话，因为要计算4096维的向量，计算量很大，所以建立一个图像检索模型很不经济。但是可以用监督学习的方法训练一个自动编码器，把它变成2进制编码，用这个来进行图像的检索就更好，比在传统训练集上得到的无监督学习方法更好，传统的方法只能捕获到图像的边缘，颜色等相似的信息，并不能捕获出语义相似的信息。</p>
<h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>我们的结果表明了在一个非常大而深的卷积神经网络在ImageNet数据集上，达到一个打破纪录的水平。值得注意的是，如果我们去掉网络中任何一个卷积层，都会使top-1的准确率降低2%，所以网络的深度是非常重要的。</p>
<p>为了简化我们的实验，我们并没有采取无监督预训练的方法，如果数据集够大并且做了预训练，我们的模型还可以得到更大的提升。我们可以进一步模拟人类大脑下颞叶处理视觉信息的原理，让卷积神经网络更加倾向于哺乳动物处理信息的过程。最后，可以将它用在视频序列的处理上，因为视频是一帧一帧的序列。</p>
<h4 id="上述论文中的一些方法现在已经基本不在使用了，但是他的一些思想，为后来的网络建立提供了很好的借鉴。"><a href="#上述论文中的一些方法现在已经基本不在使用了，但是他的一些思想，为后来的网络建立提供了很好的借鉴。" class="headerlink" title="上述论文中的一些方法现在已经基本不在使用了，但是他的一些思想，为后来的网络建立提供了很好的借鉴。"></a>上述论文中的一些方法现在已经基本不在使用了，但是他的一些思想，为后来的网络建立提供了很好的借鉴。</h4></div><div class="tags"><a href="/tags/机器学习"><i class="fa fa-tag">机器学习</i></a><a href="/tags/论文研读"><i class="fa fa-tag">论文研读</i></a><a href="/tags/计算机视觉"><i class="fa fa-tag">计算机视觉</i></a></div><div class="post-nav"><a class="pre" href="/2020/05/25/1085-Perfect-Sequence-25%E5%88%86/">1085 Perfect Sequence (25分)</a><a class="next" href="/2020/05/24/1083-List-Grades-25%E5%88%86/">1083 List Grades (25分)</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="author-info"><a class="info-avatar" href="/about/" title="About"><img class="nofancybox" src="/img/avatar.png"/></a><p>To be a better man.</p><a class="info-icon" href="https://twitter.com/username" title="Twitter" target="_blank" style="margin-inline:5px"> <i class="fa fa-twitter-square" style="margin-inline:5px"></i></a><a class="info-icon" href="mailto:admin@domain.com" title="Email" target="_blank" style="margin-inline:5px"> <i class="fa fa-envelope-square" style="margin-inline:5px"></i></a><a class="info-icon" href="https://github.com/username" title="Github" target="_blank" style="margin-inline:5px"> <i class="fa fa-github-square" style="margin-inline:5px"></i></a><a class="info-icon" href="/atom.xml" title="RSS" target="_blank" style="margin-inline:5px"> <i class="fa fa-rss-square" style="margin-inline:5px"></i></a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> Categories</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> Tags</i></div><div class="tagcloud"><a href="/tags/PAT-Advanced/" style="font-size: 15px;">PAT-Advanced</a> <a href="/tags/%E6%A0%91/" style="font-size: 15px;">树</a> <a href="/tags/dfs/" style="font-size: 15px;">dfs</a> <a href="/tags/%E4%BA%8C%E5%88%86/" style="font-size: 15px;">二分</a> <a href="/tags/%E5%9B%BE%E8%AE%BA/" style="font-size: 15px;">图论</a> <a href="/tags/%E8%BF%9E%E9%80%9A%E5%88%86%E9%87%8F/" style="font-size: 15px;">连通分量</a> <a href="/tags/%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">排序</a> <a href="/tags/%E6%A8%A1%E6%8B%9F/" style="font-size: 15px;">模拟</a> <a href="/tags/map/" style="font-size: 15px;">map</a> <a href="/tags/%E6%A0%91%E7%9A%84%E7%9B%B4%E5%BE%84/" style="font-size: 15px;">树的直径</a> <a href="/tags/%E9%9B%86%E5%90%88/" style="font-size: 15px;">集合</a> <a href="/tags/%E9%93%BE%E8%A1%A8/" style="font-size: 15px;">链表</a> <a href="/tags/%E6%80%9D%E7%BB%B4/" style="font-size: 15px;">思维</a> <a href="/tags/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/" style="font-size: 15px;">动态规划</a> <a href="/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2/" style="font-size: 15px;">字符串</a> <a href="/tags/%E6%99%BA%E5%8A%9B%E9%A2%98/" style="font-size: 15px;">智力题</a> <a href="/tags/%E5%BF%AB%E6%8E%92/" style="font-size: 15px;">快排</a> <a href="/tags/%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">插入排序</a> <a href="/tags/%E5%A0%86/" style="font-size: 15px;">堆</a> <a href="/tags/%E5%B9%B6%E6%9F%A5%E9%9B%86/" style="font-size: 15px;">并查集</a> <a href="/tags/%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97/" style="font-size: 15px;">优先队列</a> <a href="/tags/%E6%95%A3%E5%88%97/" style="font-size: 15px;">散列</a> <a href="/tags/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F/" style="font-size: 15px;">拓扑排序</a> <a href="/tags/Git/" style="font-size: 15px;">Git</a> <a href="/tags/%E8%A7%84%E8%8C%83/" style="font-size: 15px;">规范</a> <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">机器学习</a> <a href="/tags/%E6%9C%80%E7%9F%AD%E8%B7%AF/" style="font-size: 15px;">最短路</a> <a href="/tags/Dijkstra/" style="font-size: 15px;">Dijkstra</a> <a href="/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/" style="font-size: 15px;">数据库</a> <a href="/tags/mongodb/" style="font-size: 15px;">mongodb</a> <a href="/tags/elasticsearch/" style="font-size: 15px;">elasticsearch</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Tableau%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/" style="font-size: 15px;">Tableau数据分析</a> <a href="/tags/cookie/" style="font-size: 15px;">cookie</a> <a href="/tags/session/" style="font-size: 15px;">session</a> <a href="/tags/UML/" style="font-size: 15px;">UML</a> <a href="/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/" style="font-size: 15px;">软件工程</a> <a href="/tags/servlet/" style="font-size: 15px;">servlet</a> <a href="/tags/OS/" style="font-size: 15px;">OS</a> <a href="/tags/%E5%B0%8F%E7%8E%A9%E5%85%B7/" style="font-size: 15px;">小玩具</a> <a href="/tags/%E5%9B%9E%E6%BA%AF/" style="font-size: 15px;">回溯</a> <a href="/tags/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/" style="font-size: 15px;">贪心算法</a> <a href="/tags/%E5%8C%BA%E9%97%B4%E9%97%AE%E9%A2%98/" style="font-size: 15px;">区间问题</a> <a href="/tags/%E4%BA%8C%E5%8F%89%E6%A0%91/" style="font-size: 15px;">二叉树</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">深度学习</a> <a href="/tags/%E5%BE%AA%E7%8E%AF%E5%BA%8F%E5%88%97%E6%A8%A1%E5%9E%8B/" style="font-size: 15px;">循环序列模型</a> <a href="/tags/CNN/" style="font-size: 15px;">CNN</a> <a href="/tags/%E7%99%BD%E7%9B%92%E6%B5%8B%E8%AF%95/" style="font-size: 15px;">白盒测试</a> <a href="/tags/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">目标检测</a> <a href="/tags/%E8%AE%BA%E6%96%87%E7%A0%94%E8%AF%BB/" style="font-size: 15px;">论文研读</a> <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/" style="font-size: 15px;">计算机视觉</a> <a href="/tags/STL/" style="font-size: 15px;">STL</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> Recent</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/12/24/C-STL%E4%B9%8Bupper-bound%E5%92%8Clower-bound/">C++STL之lower_bound & upper_bound</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/12/14/%E3%80%90OS%E3%80%91%E7%AC%AC%E4%B8%89%E5%A4%A9-%E8%BF%9B%E5%85%A532%E4%BD%8D%E6%A8%A1%E5%BC%8F%E5%B9%B6%E5%AF%BC%E5%85%A5c%E8%AF%AD%E8%A8%80/">【OS】第三天 进入32位模式并导入c语言</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/12/14/%E3%80%90OS%E3%80%91%E7%AC%AC%E4%BA%8C%E5%A4%A9-%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0%E4%B8%8Emakefile%E5%85%A5%E9%97%A8/">【OS】第二天 汇编语言学习与makefile入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/12/14/%E3%80%90OS%E3%80%91%E7%AC%AC%E4%B8%80%E5%A4%A9-%E4%BB%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E5%88%B0%E6%B1%87%E7%BC%96%E7%A8%8B%E5%BA%8F%E5%85%A5%E9%97%A8/">【OS】第一天 从计算机结构到汇编程序入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/29/%E3%80%90%E9%93%BE%E8%A1%A8%E6%80%BB%E7%BB%93%E3%80%91%E5%BF%AB%E6%85%A2%E6%8C%87%E9%92%88%E5%B0%B1%E6%98%AF%E7%89%9B%EF%BD%9E/">【链表总结】快慢指针就是牛～</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/29/%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E9%9D%9E%E9%80%92%E5%BD%92%E9%81%8D%E5%8E%86/">二叉树的非递归遍历</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/25/%E3%80%90%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E3%80%91%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%E4%BA%8C%EF%BC%9A%E5%8C%BA%E9%97%B4%E9%97%AE%E9%A2%98/">【贪心算法】贪心算法系列二：区间问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/08/25/%E3%80%90%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E3%80%91%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%B3%BB%E5%88%97%E4%B8%80/">【贪心算法】贪心算法系列一</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/07/03/%E3%80%90%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%E3%80%91%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95%E6%80%BB%E7%BB%93/">【回溯算法】回溯算法总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/06/21/%E3%80%90%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E3%80%91%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%E6%80%BB%E7%BB%93/">【动态规划】动态规划总结</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> Links</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/." rel="nofollow">Xinsteinのblog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0"></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/latest/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js?v=1.0.0" successtext="Copy Successed!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css?v=1.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>